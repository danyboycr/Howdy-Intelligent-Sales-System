# -*- coding: utf-8 -*-
"""howdy_intelligence_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EbQHw_nHK2nK2DkDD2Z4avuA2ZwiH9Ed
"""

# 01 - IMPORT LIBRARIES
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import OneHotEncoder

# 02 - LOAD DATASET
import pandas as pd

df = pd.read_excel("Howdy_DF.xlsx")

# 1. Updated: Select features and target
features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type",
    "Brand"
]

target = "Total_Sales_PKR"

# 2. One-hot encode categorical columns (now includes Brand)
df_encoded = pd.get_dummies(df[features], columns=["Promotion_Type", "Outlet_Type", "Brand"], drop_first=True)

# 3. Prepare X (features) and y (target)
X = df_encoded
y = df[target]

# Check shape
print("Feature shape:", X.shape)
print("Target shape:", y.shape)

# 2. Light EDA before we move onto Power BI.
plt.figure(figsize=(10, 6))
sns.heatmap(df[[
    "Total_Sales_PKR",
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count"
]].corr(), annot=True, cmap="coolwarm")
plt.title("Correlation Matrix")
plt.show()

"""**Train Linear Regression**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error

lr = LinearRegression()
lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

# Evaluation
print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

pd.DataFrame({
    "Feature": X.columns,
    "Coefficient": lr.coef_
})

import seaborn as sns
import matplotlib.pyplot as plt

df_results = X_test.copy()
df_results["Actual"] = y_test
df_results["Predicted"] = y_pred
df_results["Brand"] = df.loc[df_results.index, "Brand"]  # attach brand back

brands = df_results["Brand"].unique()
plt.figure(figsize=(14, 8))
for brand in brands:
    brand_df = df_results[df_results["Brand"] == brand]
    sns.scatterplot(x=brand_df["Actual"], y=brand_df["Predicted"], label=brand, alpha=0.7)

plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.title("Actual vs Predicted Sales by Brand")
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.legend()
plt.tight_layout()
plt.show()

"""**Training Segmented Models by Brand**

---


"""

tlt_df = df[df["Brand"] == "The Lost Tribe - F-11"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

tlt_encoded = pd.get_dummies(tlt_df[features], columns=["Promotion_Type", "Outlet_Type"], drop_first=True)

X_tlt = tlt_encoded
y_tlt = tlt_df[target]

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X_tlt, y_tlt, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

# Evaluation
print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import pandas as pd

coeff_df = pd.DataFrame({
    "Feature": X_tlt.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

print(coeff_df)

import matplotlib.pyplot as plt
import seaborn as sns

# Reuse y_test and y_pred from the TLT model
plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # perfect fit line
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.title("TLT: Actual vs Predicted Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

# 02 - GreenBae's segmented regression
greenbae_df = df[df["Brand"] == "Greenbae - F-11"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

greenbae_encoded = pd.get_dummies(
    greenbae_df[features],
    columns=["Promotion_Type", "Outlet_Type"],
    drop_first=True
)

X_greenbae = greenbae_encoded
y_greenbae = greenbae_df[target]

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X_greenbae, y_greenbae, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import pandas as pd

pd.DataFrame({
    "Feature": X_greenbae.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')  # Perfect prediction line
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.title("Greenbae: Actual vs Predicted Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

# 03 - Rare's segmented regression
rare_df = df[df["Brand"] == "Rare - F-6"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

rare_encoded = pd.get_dummies(
    rare_df[features],
    columns=["Promotion_Type", "Outlet_Type"],
    drop_first=True
)

X_rare = rare_encoded
y_rare = rare_df[target]

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X_rare, y_rare, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluation
print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.title("Rare: Actual vs Predicted Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd

pd.DataFrame({
    "Feature": X_rare.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

# 04 - Howdy Centauras's segmented regression

howdy_c_df = df[df["Brand"] == "Howdy - Centaurus Mall"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

howdy_c_encoded = pd.get_dummies(
    howdy_c_df[features],
    columns=["Promotion_Type", "Outlet_Type"],
    drop_first=True
)

X_howdy_c = howdy_c_encoded
y_howdy_c = howdy_c_df[target]

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X_howdy_c, y_howdy_c, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluation
print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.title("Howdy - Centaurus Mall: Actual vs Predicted Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd

pd.DataFrame({
    "Feature": X_howdy_c.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

# 05 - Howdy F7's segmented regression

howdy_f7_df = df[df["Brand"] == "Howdy F7 Branch"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

howdy_f7_encoded = pd.get_dummies(
    howdy_f7_df[features],
    columns=["Promotion_Type", "Outlet_Type"],
    drop_first=True
)

X_howdy_f7 = howdy_f7_encoded
y_howdy_f7 = howdy_f7_df[target]

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X_howdy_f7, y_howdy_f7, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# Evaluation
print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.title("Howdy - F7 Branch: Actual vs Predicted Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd

pd.DataFrame({
    "Feature": X_howdy_f7.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

# 06 - Howdy Giga segmented regression
howdy_giga_df = df[df["Brand"] == "Howdy - Giga Mall"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

howdy_giga_encoded = pd.get_dummies(
    howdy_giga_df[features],
    columns=["Promotion_Type", "Outlet_Type"],
    drop_first=True
)

X_howdy_giga = howdy_giga_encoded
y_howdy_giga = howdy_giga_df[target]

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

X_train, X_test, y_train, y_test = train_test_split(X_howdy_giga, y_howdy_giga, test_size=0.2, random_state=42)

model = LinearRegression()
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

print("RÂ² Score:", r2_score(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=y_pred, alpha=0.7)
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')
plt.xlabel("Actual Sales (PKR)")
plt.ylabel("Predicted Sales (PKR)")
plt.title("Howdy - Giga Mall: Actual vs Predicted Sales")
plt.grid(True)
plt.tight_layout()
plt.show()

import pandas as pd

pd.DataFrame({
    "Feature": X_howdy_giga.columns,
    "Coefficient": model.coef_
}).sort_values(by="Coefficient", ascending=False)

"""**Howdy F7 RandomForest due to low RÂ² Score relatively in the previous linear regression model**"""

# - Howdy F7 RandomForest
howdy_f7_df = df[df["Brand"] == "Howdy F7 Branch"].copy()

features = [
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]

target = "Total_Sales_PKR"

f7_encoded = pd.get_dummies(
    howdy_f7_df[features],
    columns=["Promotion_Type", "Outlet_Type"],
    drop_first=True
)

X_f7 = f7_encoded
y_f7 = howdy_f7_df[target]

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

# Train/Test Split
X_train, X_test, y_train, y_test = train_test_split(X_f7, y_f7, test_size=0.2, random_state=42)

# Random Forest Model
rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)
y_pred_rf = rf_model.predict(X_test)

# Evaluation
print("Random Forest RÂ²:", r2_score(y_test, y_pred_rf))
print("Random Forest RMSE:", np.sqrt(mean_squared_error(y_test, y_pred_rf)))

import pandas as pd

pd.DataFrame({
    "Feature": X_f7.columns,
    "Importance": rf_model.feature_importances_
}).sort_values(by="Importance", ascending=False)

"""**SHAP for the trained Random Forest model**"""

import shap

explainer = shap.TreeExplainer(rf_model)

# Calculate SHAP values for the test set
shap_values = explainer.shap_values(X_test)

shap.summary_plot(shap_values, X_test, plot_type="bar")

shap.summary_plot(shap_values, X_test)

# Pick a row from X_test to explain (e.g., index 5)
row_to_explain = X_test.iloc[5]

# Visual force plot
shap.initjs()
shap.force_plot(explainer.expected_value, shap_values[5], row_to_explain)

"""**Simulation Use Case â€“ Howdy F7 Branch**"""

# ðŸ”¹ 1. Train RF Model (already done)
from sklearn.ensemble import RandomForestRegressor

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# ðŸ”¹ 2. Initialize SHAP
explainer = shap.TreeExplainer(rf_model)

# ðŸ”¹ 3. Create feature template
feature_template = X_f7.iloc[0:1].copy()
feature_template = feature_template.astype(float)
feature_template[:] = 0

# ðŸ”¹ 4. Simulation!
def simulate_outlet(rf_model, explainer, feature_template, *,
                    rain, staff_count, foot_traffic, conversion_rate,
                    compliance_score, avg_order_value, promo_type, outlet_type):

    import pandas as pd
    import shap

    new_data = feature_template.copy()
    new_data["Rain"] = int(rain)
    new_data["Staff_Count"] = staff_count
    new_data["Foot_Traffic_Adjusted"] = foot_traffic
    new_data["Simulated_Conversion_Rate"] = conversion_rate
    new_data["Compliance_Score"] = compliance_score
    new_data["Avg_Order_Value"] = avg_order_value

    for col in new_data.columns:
        if "Promotion_Type_" in col or "Outlet_Type_" in col:
            new_data[col] = 0

    if f"Promotion_Type_{promo_type}" in new_data.columns:
        new_data[f"Promotion_Type_{promo_type}"] = 1
    if f"Outlet_Type_{outlet_type}" in new_data.columns:
        new_data[f"Outlet_Type_{outlet_type}"] = 1

    prediction = rf_model.predict(new_data)[0]
    print(f"\nðŸ“ˆ Predicted Sales: {prediction:,.0f} PKR")

    shap.initjs()
    shap.force_plot(explainer.expected_value, explainer.shap_values(new_data)[0], new_data)


simulate_outlet(
    rf_model=rf_model,
    explainer=explainer,
    feature_template=feature_template,
    rain=True,
    staff_count=3,
    foot_traffic=400,
    conversion_rate=0.12,
    compliance_score=70,
    avg_order_value=1150,
    promo_type="Combo",
    outlet_type="Standalone"
)

"""**Simulation Scenario Grid**"""

# Filter the full dataset for Howdy F7 Branch
df_f7 = df[df["Brand"] == "Howdy F7 Branch"].copy()

# Check what promo types are available (optional)
print(df_f7["Promotion_Type"].value_counts())

# One-hot encode input features (without dropping anything)
X_f7 = pd.get_dummies(df_f7[[
    "Foot_Traffic_Adjusted",
    "Simulated_Conversion_Rate",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]], drop_first=False)

# Inject any missing promo types (needed only for simulation)
for col in ["Promotion_Type_None"]:
    if col not in X_f7.columns:
        X_f7[col] = 0

y_f7 = df_f7["Total_Sales_PKR"]

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X_f7, y_f7, test_size=0.2, random_state=42)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

import pandas as pd
import itertools

# Simulation values
promo_types = ["Promotion_Type_Combo", "Promotion_Type_Platinum Debit 40% Off", "Promotion_Type_None"]
rain_options = [True, False]
staff_counts = [2, 3, 4]
foot_traffic_values = [300, 400, 500]
conversion_rates = [0.10, 0.12, 0.14]

# Build the grid
scenarios = list(itertools.product(promo_types, rain_options, staff_counts, foot_traffic_values, conversion_rates))
grid_df = pd.DataFrame(scenarios, columns=[
    "Promo_Type", "Rain", "Staff_Count", "Foot_Traffic", "Conversion_Rate"
])

grid_df["Compliance_Score"] = 70
grid_df["Avg_Order_Value"] = 1150
grid_df["Outlet_Type"] = "Standalone"

predictions = []

for _, row in grid_df.iterrows():
    temp_input = X_f7.iloc[0:1].copy()
    temp_input = temp_input.astype(float)
    temp_input[:] = 0

    # Assign inputs
    temp_input["Rain"] = int(row["Rain"])
    temp_input["Staff_Count"] = row["Staff_Count"]
    temp_input["Foot_Traffic_Adjusted"] = row["Foot_Traffic"]
    temp_input["Simulated_Conversion_Rate"] = row["Conversion_Rate"]
    temp_input["Compliance_Score"] = row["Compliance_Score"]
    temp_input["Avg_Order_Value"] = row["Avg_Order_Value"]

    # Reset all promo and outlet encodings
    for col in temp_input.columns:
        if "Promotion_Type_" in col or "Outlet_Type_" in col:
            temp_input[col] = 0

    # Set correct promo/outlet type
    promo_col = row["Promo_Type"]
    outlet_col = f"Outlet_Type_{row['Outlet_Type']}"

    if promo_col in temp_input.columns:
        temp_input[promo_col] = 1
    if outlet_col in temp_input.columns:
        temp_input[outlet_col] = 1

    # Predict
    pred = rf_model.predict(temp_input)[0]
    predictions.append(round(pred))

# Store predictions
grid_df["Predicted_Sales"] = predictions

def classify_risk(sales):
    if sales < 100000:
        return "ðŸ”´ High Risk"
    elif sales < 150000:
        return "ðŸŸ¡ Moderate"
    else:
        return "ðŸŸ¢ Low Risk"

grid_df["Risk_Flag"] = grid_df["Predicted_Sales"].apply(classify_risk)

# Sort and display top
grid_df_sorted = grid_df.sort_values(by="Predicted_Sales", ascending=False)
grid_df.groupby("Promo_Type")["Predicted_Sales"].mean().sort_values(ascending=False)
display(grid_df_sorted.head(10))

top_by_promo = grid_df.groupby("Promo_Type").apply(lambda d: d.sort_values("Predicted_Sales", ascending=False).head(1)).reset_index(drop=True)

plt.figure(figsize=(12, 6))
sns.barplot(data=top_by_promo, x="Predicted_Sales", y="Promo_Type", hue="Rain")
plt.title("Best Predicted Scenario per Promo Type â€“ Howdy F7")
plt.tight_layout()
plt.show()

grid_df.groupby("Promo_Type").apply(lambda df: df.sort_values("Predicted_Sales", ascending=False).head(1))[[
    "Promo_Type", "Rain", "Staff_Count", "Foot_Traffic", "Conversion_Rate", "Predicted_Sales", "Risk_Flag"
]]

"""**Simulated Scenario Insights â€“ Howdy F7**

**To understand the impact of different marketing strategies, we simulated sales for the Howdy F7 outlet using a trained Random Forest model. We varied foot traffic, weather, staffing, and promotion type. The model predicted that the Combo promotion consistently outperformed both Platinum Debit 40% Off and No Promotion, achieving up to â‚¨122,000 in simulated sales. This demonstrates the modelâ€™s ability to support strategic planning by quantifying the revenue uplift potential of specific interventions under varying real-world conditions.**

**Time-Based Feature Engineering**
"""

df_f7["Date"] = pd.to_datetime(df_f7["Date"])
df_f7 = df_f7.sort_values("Date")

# Lagged features (yesterday's data)
df_f7["Conversion_Rate_Lag1"] = df_f7["Simulated_Conversion_Rate"].shift(1)

# Rolling average of past 3 days
df_f7["Conversion_Rate_MA3"] = df_f7["Simulated_Conversion_Rate"].rolling(window=3).mean()

# (Optional) Lagged traffic
df_f7["Foot_Traffic_Lag1"] = df_f7["Foot_Traffic_Adjusted"].shift(1)

df_f7 = df_f7.dropna(subset=["Conversion_Rate_Lag1", "Conversion_Rate_MA3", "Foot_Traffic_Lag1"])

# One-hot encode with time-aware inputs
X_f7 = pd.get_dummies(df_f7[[
    "Foot_Traffic_Adjusted",
    "Foot_Traffic_Lag1",
    "Simulated_Conversion_Rate",
    "Conversion_Rate_Lag1",
    "Conversion_Rate_MA3",
    "Avg_Order_Value",
    "Compliance_Score",
    "Staff_Count",
    "Rain",
    "Promotion_Type",
    "Outlet_Type"
]], drop_first=False)

# Inject any missing columns to match model input structure
for col in ["Promotion_Type_None", "Promotion_Type_Combo", "Promotion_Type_Platinum Debit 40% Off"]:
    if col not in X_f7.columns:
        X_f7[col] = 0

y_f7 = df_f7["Total_Sales_PKR"]

from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor

X_train, X_test, y_train, y_test = train_test_split(X_f7, y_f7, test_size=0.2, random_state=42)

rf_model = RandomForestRegressor(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

import sklearn.metrics as skm

from sklearn.metrics import r2_score, mean_squared_error
import numpy as np

y_pred = rf_model.predict(X_test)

r2 = r2_score(y_test, y_pred)
mse = mean_squared_error(y_test, y_pred)
rmse = np.sqrt(mse)

print("ðŸ“Š RÂ² Score:", round(r2, 4))
print("ðŸ“‰ RMSE:", round(rmse, 2))

"""**Time Aware Model**"""

import pandas as pd
import itertools

# Define simulation ranges
promo_types = ["Promotion_Type_Combo", "Promotion_Type_Platinum Debit 40% Off", "Promotion_Type_None"]
rain_options = [True, False]
staff_counts = [2, 3, 4]
foot_traffic_values = [300, 400, 500]
conversion_rates = [0.10, 0.12, 0.14]
conversion_lag = [0.10, 0.11, 0.13]
conversion_ma3 = [0.11, 0.12, 0.13]
foot_traffic_lag = [250, 300, 400]

# Create scenario combinations
scenarios = list(itertools.product(
    promo_types, rain_options, staff_counts, foot_traffic_values,
    conversion_rates, conversion_lag, conversion_ma3, foot_traffic_lag
))

# Build DataFrame
grid_df = pd.DataFrame(scenarios, columns=[
    "Promo_Type", "Rain", "Staff_Count", "Foot_Traffic",
    "Conversion_Rate", "Lagged_Conversion", "MA3_Conversion", "Foot_Traffic_Lag"
])

# Add constants
grid_df["Compliance_Score"] = 70
grid_df["Avg_Order_Value"] = 1150
grid_df["Outlet_Type"] = "Standalone"

predictions = []

for _, row in grid_df.iterrows():
    temp_input = X_f7.iloc[0:1].copy()
    temp_input = temp_input.astype(float)
    temp_input[:] = 0

    temp_input["Rain"] = int(row["Rain"])
    temp_input["Staff_Count"] = row["Staff_Count"]
    temp_input["Foot_Traffic_Adjusted"] = row["Foot_Traffic"]
    temp_input["Foot_Traffic_Lag1"] = row["Foot_Traffic_Lag"]
    temp_input["Simulated_Conversion_Rate"] = row["Conversion_Rate"]
    temp_input["Conversion_Rate_Lag1"] = row["Lagged_Conversion"]
    temp_input["Conversion_Rate_MA3"] = row["MA3_Conversion"]
    temp_input["Compliance_Score"] = row["Compliance_Score"]
    temp_input["Avg_Order_Value"] = row["Avg_Order_Value"]

    # Reset all dummies
    for col in temp_input.columns:
        if "Promotion_Type_" in col or "Outlet_Type_" in col:
            temp_input[col] = 0

    # Encode promo and outlet
    promo_col = row["Promo_Type"]
    outlet_col = f"Outlet_Type_{row['Outlet_Type']}"

    if promo_col in temp_input.columns:
        temp_input[promo_col] = 1
    if outlet_col in temp_input.columns:
        temp_input[outlet_col] = 1

    # Predict
    pred = rf_model.predict(temp_input)[0]
    predictions.append(round(pred))

# Store predictions
grid_df["Predicted_Sales"] = predictions

def classify_risk(sales):
    if sales < 100000:
        return "ðŸ”´ High Risk"
    elif sales < 150000:
        return "ðŸŸ¡ Moderate"
    else:
        return "ðŸŸ¢ Low Risk"

grid_df["Risk_Flag"] = grid_df["Predicted_Sales"].apply(classify_risk)

import seaborn as sns
import matplotlib.pyplot as plt

top = grid_df_sorted.groupby("Promo_Type").apply(lambda d: d.sort_values("Predicted_Sales", ascending=False).head(1)).reset_index(drop=True)

plt.figure(figsize=(12, 6))
sns.barplot(data=top, x="Predicted_Sales", y="Promo_Type", hue="Rain")
plt.title("Best Predicted Scenario per Promo (Time-Aware Model)")
plt.tight_layout()
plt.show()

plt.figure(figsize=(10, 6))
sns.countplot(data=grid_df, x="Promo_Type", hue="Risk_Flag", order=grid_df["Promo_Type"].unique(),
              hue_order=["ðŸ”´ High Risk", "ðŸŸ¡ Moderate", "ðŸŸ¢ Low Risk"],
              palette=["red", "gold", "green"])
plt.title("Risk Flag Distribution by Promotion Type")
plt.ylabel("Number of Scenarios")
plt.xticks(rotation=30)
plt.tight_layout()
plt.show()

"""**We re-ran our scenario simulation using a time-aware Random Forest model that considers both current-day and historical patterns (e.g., lagged conversion rate). This enabled us to compare promo strategies not just by static performance, but by their temporal dynamics.0.**

**Sensitivity Analysis**
"""

# Define a neutral base input row (as a reference point)
base_input = X_f7.iloc[0:1].copy()
base_input[:] = 0  # Reset all values

# Set constant values
base_input["Foot_Traffic_Adjusted"] = 400
base_input["Foot_Traffic_Lag1"] = 350
base_input["Simulated_Conversion_Rate"] = 0.12
base_input["Conversion_Rate_Lag1"] = 0.10
base_input["Conversion_Rate_MA3"] = 0.11
base_input["Avg_Order_Value"] = 1150
base_input["Compliance_Score"] = 70
base_input["Staff_Count"] = 3
base_input["Rain"] = 0
base_input["Promotion_Type_Combo"] = 1
base_input["Outlet_Type_Standalone"] = 1

"""**Sensitivity to Foot Traffic**




"""

import numpy as np
import matplotlib.pyplot as plt

traffic_range = np.arange(100, 650, 50)
sales_predictions = []

for ft in traffic_range:
    temp = base_input.copy()
    temp["Foot_Traffic_Adjusted"] = ft
    pred = rf_model.predict(temp)[0]
    sales_predictions.append(pred)

# Plot
plt.figure(figsize=(8,5))
plt.plot(traffic_range, sales_predictions, marker='o')
plt.title("Sensitivity Analysis: Foot Traffic vs Predicted Sales")
plt.xlabel("Foot Traffic")
plt.ylabel("Predicted Sales (PKR)")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Conversion Rate**

"""

conv_range = np.round(np.arange(0.05, 0.21, 0.01), 2)
conv_sales = []

for cr in conv_range:
    temp = base_input.copy()
    temp["Simulated_Conversion_Rate"] = cr
    pred = rf_model.predict(temp)[0]
    conv_sales.append(pred)

plt.figure(figsize=(8,5))
plt.plot(conv_range, conv_sales, marker='o', color="green")
plt.title("Sensitivity Analysis: Conversion Rate vs Sales")
plt.xlabel("Conversion Rate")
plt.ylabel("Predicted Sales (PKR)")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Staff Count**"""

staff_range = range(1, 6)
staff_sales = []

for sc in staff_range:
    temp = base_input.copy()
    temp["Staff_Count"] = sc
    pred = rf_model.predict(temp)[0]
    staff_sales.append(pred)

plt.figure(figsize=(8,5))
plt.plot(staff_range, staff_sales, marker='o', color="orange")
plt.title("Sensitivity Analysis: Staff Count vs Sales")
plt.xlabel("Staff Count")
plt.ylabel("Predicted Sales (PKR)")
plt.grid(True)
plt.tight_layout()
plt.show()

"""**Rain vs No Rain**"""

rain_sales = []

for rain in [0, 1]:
    temp = base_input.copy()
    temp["Rain"] = rain
    pred = rf_model.predict(temp)[0]
    rain_sales.append(pred)

plt.bar(["No Rain", "Rain"], rain_sales, color=["skyblue", "gray"])
plt.title("Sensitivity Analysis: Rain vs Sales")
plt.ylabel("Predicted Sales (PKR)")
plt.tight_layout()
plt.show()

"""**Our sensitivity analysis revealed that conversion rate is the most influential variable, exhibiting a stepwise increase in sales around a 14% threshold. Foot traffic and staff count had minimal individual effect, suggesting diminishing returns or reliance on downstream variables. Rain caused a slight sales dip but remained within the moderate risk band. These findings support focused efforts on improving conversion efficiency over expanding headcount.**

**Recommendation Engine**
"""

def recommend(row):
    # High-performance case
    if row["Predicted_Sales"] > 118000:
        return "âœ… Maintain Strategy"

    # Rain scenario with low sales
    elif row["Rain"] == 1 and row["Predicted_Sales"] < 110000:
        return "ðŸ’¡ Use Debit 40% Promo in Rain"

    # High staff, low output
    elif row["Staff_Count"] >= 4 and row["Predicted_Sales"] < 115000:
        return "ðŸ“‰ Reduce Staff â€“ Inefficient Load"

    # Low conversion under Combo
    elif row["Promo_Type"] == "Promotion_Type_Combo" and row["Conversion_Rate"] < 0.12:
        return "ðŸ’¡ Switch Promo â€“ Combo Underperforming"

    # Default case
    else:
        return "ðŸ“Œ Monitor â€“ No Clear Action"

# Re-merge or pull original promo info into grid_df
if "Promo_Type" not in grid_df.columns:
    grid_df["Promo_Type"] = [row["Promo_Type"] for _, row in grid_df.iterrows()]

grid_df["Recommendation"] = grid_df.apply(recommend, axis=1)

display(grid_df[[
    "Promo_Type", "Rain", "Staff_Count", "Foot_Traffic",
    "Conversion_Rate", "Predicted_Sales", "Risk_Flag", "Recommendation"
]].sort_values(by="Predicted_Sales", ascending=True).head(10))

grid_df.sample(10)[[
    "Promo_Type", "Rain", "Staff_Count", "Foot_Traffic",
    "Conversion_Rate", "Predicted_Sales", "Risk_Flag", "Recommendation"
]]

"""**The recommendation engine flagged multiple scenarios where staff count exceeded operational efficiency. Even with a conversion rate of 14% and traffic of 500, predicted sales plateaued below â‚¨101K. In such cases, the system intelligently recommends reducing staffing levels to match expected output, optimizing labor costs without compromising sales potential.**"""